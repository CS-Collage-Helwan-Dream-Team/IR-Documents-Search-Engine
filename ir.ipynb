{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import lib\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "from tabulate import tabulate  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Abdelrahman\n",
      "[nltk_data]     Mostafa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term found in query: antony\n",
      "Term found in query: brutus\n",
      "Term found in query: caeser\n",
      "Term found in query: cleopatra\n",
      "Term found in query: mercy\n",
      "Term found in query: worser\n",
      "Error: Malformed boolean query or term not found. Please check your query syntax and terms.\n",
      "Matched Documents (Boolean Query): set()\n"
     ]
    }
   ],
   "source": [
    "#Read 10 files (.txt)\n",
    "def read_files(directory):\n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "    data = {}\n",
    "    for file in files:\n",
    "        with open(os.path.join(directory, file), 'r') as f:\n",
    "            data[file] = f.read()\n",
    "    return data\n",
    "\n",
    "#Apply tokenization and Step 3: Apply stemming\n",
    "def tokenize_and_stem(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "#Build positional index\n",
    "def build_positional_index(data):\n",
    "    positional_index = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for doc, text in data.items():\n",
    "        tokens = tokenize_and_stem(text)\n",
    "        for position, term in enumerate(tokens):\n",
    "            positional_index[term][doc].append(position + 1)\n",
    "\n",
    "    return positional_index\n",
    "\n",
    "#Compute term frequency\n",
    "def compute_term_frequency(positional_index):\n",
    "    term_frequency = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for term, docs in positional_index.items():\n",
    "        for doc, positions in docs.items():\n",
    "            term_frequency[term][doc] = len(positions)\n",
    "\n",
    "    return term_frequency\n",
    "\n",
    "#Compute IDF\n",
    "def compute_idf(data, term):\n",
    "    total_docs = len(data)\n",
    "    doc_count = sum(1 for doc, positions in positional_index[term].items() if positions)\n",
    "    return math.log10(total_docs / doc_count) if doc_count != 0 else 0\n",
    "\n",
    "#Compute TF-IDF matrix\n",
    "def compute_tf_idf(term_frequency, idf):\n",
    "    tf_idf_matrix = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    for term, docs in term_frequency.items():\n",
    "        for doc, tf in docs.items():\n",
    "            tf_idf_matrix[term][doc] = tf * idf[term]\n",
    "\n",
    "    return tf_idf_matrix\n",
    "\n",
    "#Allow users to write a phrase query\n",
    "def phrase_query(positional_index, query):\n",
    "    terms = tokenize_and_stem(query)\n",
    "    matched_docs = set(positional_index[terms[0]])\n",
    "\n",
    "    for term in terms[1:]:\n",
    "        matched_docs.intersection_update(positional_index[term])\n",
    "\n",
    "    return matched_docs\n",
    "\n",
    "#Allow users to write boolean query\n",
    "def boolean_query(positional_index, query):\n",
    "    query_terms = re.findall(r'\\bAND\\b|\\bOR\\b|\\bNOT\\b|\\(|\\)|\\b\\w+\\b', query)  # Remove uppercase conversion\n",
    "    stack = []\n",
    "    operators = {'AND', 'OR', 'NOT'}\n",
    "\n",
    "    try:\n",
    "        for term in query_terms:\n",
    "            term_lower = term.lower()  # Convert the term to lowercase\n",
    "            if term == '(' or term == 'NOT':\n",
    "                stack.append(term)\n",
    "            elif term == 'AND' or term == 'OR':\n",
    "                while stack and stack[-1] in operators and operators.index(stack[-1]) >= operators.index(term):\n",
    "                    operator = stack.pop()\n",
    "                    if operator == 'AND':\n",
    "                        stack.append(set(stack.pop()) & set(stack.pop()))\n",
    "                    elif operator == 'OR':\n",
    "                        stack.append(set(stack.pop()) | set(stack.pop()))\n",
    "                stack.append(term)\n",
    "            elif term == ')':\n",
    "                while stack and stack[-1] != '(':\n",
    "                    operator = stack.pop()\n",
    "                    if operator == 'AND':\n",
    "                        stack.append(set(stack.pop()) & set(stack.pop()))\n",
    "                    elif operator == 'OR':\n",
    "                        stack.append(set(stack.pop()) | set(stack.pop()))\n",
    "                stack.pop()  # Remove the '('\n",
    "            else:\n",
    "                print(\"Term found in query:\", term_lower)\n",
    "                stack.append(set(positional_index[term_lower]))\n",
    "\n",
    "        while stack:\n",
    "            operator = stack.pop()\n",
    "            if operator == 'AND':\n",
    "                stack.append(set(stack.pop()) & set(stack.pop()))\n",
    "            elif operator == 'OR':\n",
    "                stack.append(set(stack.pop()) | set(stack.pop()))\n",
    "\n",
    "        return stack[0] if stack else set()\n",
    "\n",
    "    except (IndexError, KeyError):\n",
    "        print(\"Error: Malformed boolean query or term not found. Please check your query syntax and terms.\")\n",
    "        return set()\n",
    "\n",
    "\n",
    "#Compute similarity between the query and matched documents\n",
    "def compute_similarity(query_vector, doc_vector):\n",
    "    dot_product = np.dot(query_vector, doc_vector)\n",
    "    query_norm = np.linalg.norm(query_vector)\n",
    "    doc_norm = np.linalg.norm(doc_vector)\n",
    "\n",
    "    if query_norm == 0 or doc_norm == 0:\n",
    "        return 0.0\n",
    "\n",
    "    similarity = dot_product / (query_norm * doc_norm)\n",
    "    return similarity\n",
    "\n",
    "#Rank documents based on similarity score\n",
    "def rank_documents(query_vector, matched_docs, tf_idf_matrix):\n",
    "    ranked_documents = []\n",
    "\n",
    "    for doc in matched_docs:\n",
    "        doc_vector = np.array([tf_idf_matrix[term][doc] for term in tf_idf_matrix.keys()])\n",
    "        similarity_score = compute_similarity(query_vector, doc_vector)\n",
    "        ranked_documents.append((doc, similarity_score))\n",
    "\n",
    "    ranked_documents.sort(key=lambda x: x[1], reverse=True)\n",
    "    return ranked_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = r\"C:\\Users\\Abdelrahman Mostafa\\Desktop\\IR\\lastIR_project\\lastIR_project\\files\"\n",
    "data = read_files(data_directory)\n",
    "positional_index = build_positional_index(data)\n",
    "term_frequency = compute_term_frequency(positional_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Documents (Phrase Query): set()\n"
     ]
    }
   ],
   "source": [
    "# Example phrase query\n",
    "query_phrase = \"your phrase query\"\n",
    "matched_docs_phrase = phrase_query(positional_index, query_phrase)\n",
    "print(\"Matched Documents (Phrase Query):\", matched_docs_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term found in query: antony\n",
      "Term found in query: brutus\n",
      "Term found in query: caeser\n",
      "Term found in query: cleopatra\n",
      "Term found in query: mercy\n",
      "Term found in query: worser\n",
      "Error: Malformed boolean query or term not found. Please check your query syntax and terms.\n",
      "Matched Documents (Boolean Query): set()\n"
     ]
    }
   ],
   "source": [
    "# Example boolean query\n",
    "query_boolean = \"antony OR brutus OR caeser OR cleopatra OR mercy OR worser\"\n",
    "matched_docs_boolean = boolean_query(positional_index, query_boolean)\n",
    "print(\"Matched Documents (Boolean Query):\", matched_docs_boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF for each term: {'antoni': 0.5228787452803376, 'brutu': 0.5228787452803376, 'caeser': 0.3010299956639812, 'cleopatra': 1.0, 'merci': 0.3010299956639812, 'worser': 0.3979400086720376, 'fool': 0.3979400086720376, 'fear': 0.5228787452803376, 'in': 0.3979400086720376, 'rush': 0.3979400086720376, 'to': 0.3979400086720376, 'tread': 0.3979400086720376, 'where': 0.3979400086720376, 'calpurnia': 1.0, 'angel': 0.5228787452803376, 'ANTONY': 0, 'RUSH': 0, 'WORSER': 0, 'WHERE': 0}\n"
     ]
    }
   ],
   "source": [
    "# Example computation of IDF for each term\n",
    "idf = {term: compute_idf(data, term) for term in positional_index}\n",
    "print(\"IDF for each term:\", idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix:\n",
      "+--------+-------+--------+-----------+-------+--------+--------+--------+--------+--------+--------+--------+--------+-----------+-------+\n",
      "| antoni | brutu | caeser | cleopatra | merci | worser |  fool  |  fear  |   in   |  rush  |   to   | tread  | where  | calpurnia | angel |\n",
      "+--------+-------+--------+-----------+-------+--------+--------+--------+--------+--------+--------+--------+--------+-----------+-------+\n",
      "| 1.txt  | 1.txt | 1.txt  |   1.txt   | 1.txt | 1.txt  | 10.txt | 10.txt | 10.txt | 10.txt | 10.txt | 10.txt | 10.txt |   2.txt   | 7.txt |\n",
      "| 2.txt  | 2.txt | 2.txt  |           | 3.txt | 3.txt  | 7.txt  | 7.txt  | 7.txt  | 7.txt  | 7.txt  | 7.txt  | 7.txt  |           | 8.txt |\n",
      "| 6.txt  | 4.txt | 4.txt  |           | 4.txt | 4.txt  | 8.txt  | 8.txt  | 8.txt  | 8.txt  | 8.txt  | 8.txt  | 8.txt  |           | 9.txt |\n",
      "|        |       | 5.txt  |           | 5.txt | 5.txt  | 9.txt  |        | 9.txt  | 9.txt  | 9.txt  | 9.txt  | 9.txt  |           |       |\n",
      "|        |       | 6.txt  |           | 6.txt |        |        |        |        |        |        |        |        |           |       |\n",
      "+--------+-------+--------+-----------+-------+--------+--------+--------+--------+--------+--------+--------+--------+-----------+-------+\n"
     ]
    }
   ],
   "source": [
    "# Example computation of TF-IDF matrix\n",
    "tf_idf_matrix = compute_tf_idf(term_frequency, idf)\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(tabulate(tf_idf_matrix, headers=\"keys\", tablefmt=\"pretty\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
