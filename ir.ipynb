{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import lib\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "from tabulate import tabulate  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Abdelrahman\n",
      "[nltk_data]     Mostafa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read 10 files (.txt)\n",
    "def read_files(directory):\n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "    data = {}\n",
    "    for file in files:\n",
    "        with open(os.path.join(directory, file), 'r') as f:\n",
    "            data[file] = f.read()\n",
    "    return data\n",
    "\n",
    "#Apply tokenization and Step 3: Apply stemming\n",
    "def tokenize_and_stem(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "#Build positional index\n",
    "def build_positional_index(data):\n",
    "    positional_index = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for doc, text in data.items():\n",
    "        tokens = tokenize_and_stem(text)\n",
    "        for position, term in enumerate(tokens):\n",
    "            positional_index[term][doc].append(position + 1)\n",
    "\n",
    "    return positional_index\n",
    "\n",
    "#Compute term frequency\n",
    "def compute_term_frequency(positional_index):\n",
    "    term_frequency = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for term, docs in positional_index.items():\n",
    "        for doc, positions in docs.items():\n",
    "            term_frequency[term][doc] = len(positions)\n",
    "\n",
    "    return term_frequency\n",
    "\n",
    "#Compute IDF\n",
    "def compute_idf(data, term):\n",
    "    total_docs = len(data)\n",
    "    doc_count = sum(1 for doc, positions in positional_index[term].items() if positions)\n",
    "    return math.log10(total_docs / doc_count) if doc_count != 0 else 0\n",
    "\n",
    "#Compute TF-IDF matrix\n",
    "def compute_tf_idf(term_frequency, idf):\n",
    "    tf_idf_matrix = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    for term, docs in term_frequency.items():\n",
    "        for doc, tf in docs.items():\n",
    "            tf_idf_matrix[term][doc] = tf * idf[term]\n",
    "\n",
    "    return tf_idf_matrix\n",
    "\n",
    "#Allow users to write a phrase query\n",
    "def phrase_query(positional_index, query):\n",
    "    terms = tokenize_and_stem(query)\n",
    "    matched_docs = set(positional_index[terms[0]])\n",
    "\n",
    "    for term in terms[1:]:\n",
    "        matched_docs.intersection_update(positional_index[term])\n",
    "\n",
    "    return matched_docs\n",
    "\n",
    "#Allow users to write boolean query\n",
    "def boolean_query(positional_index, query):\n",
    "    query = query.lower()\n",
    "    query_tokens = tokenize_and_stem(query)\n",
    "\n",
    "    stack = []\n",
    "    operator_stack = []\n",
    "\n",
    "    for token in query_tokens:\n",
    "        if token == 'and':\n",
    "            operator_stack.append('and')\n",
    "        elif token == 'or':\n",
    "            operator_stack.append('or')\n",
    "        elif token == 'not':\n",
    "            operator_stack.append('not')\n",
    "        else:\n",
    "            if token in positional_index:\n",
    "                stack.append(set(positional_index[token].keys()))\n",
    "            else:\n",
    "                stack.append(set())\n",
    "\n",
    "    while operator_stack:\n",
    "        operator = operator_stack.pop()\n",
    "        set2 = stack.pop()\n",
    "        \n",
    "        if not stack:\n",
    "            return list(set2)\n",
    "\n",
    "        set1 = stack.pop()\n",
    "\n",
    "        if operator == 'and':\n",
    "            result = set1.intersection(set2)\n",
    "        elif operator == 'or':\n",
    "            result = set1.union(set2)\n",
    "        elif operator == 'not':\n",
    "            result = set1.difference(set2)\n",
    "\n",
    "        stack.append(result)\n",
    "\n",
    "    if stack:\n",
    "        return list(stack[0])\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Compute similarity between the query and matched documents\n",
    "def compute_similarity(query_vector, doc_vector):\n",
    "    dot_product = np.dot(query_vector, doc_vector)\n",
    "    query_norm = np.linalg.norm(query_vector)\n",
    "    doc_norm = np.linalg.norm(doc_vector)\n",
    "\n",
    "    if query_norm == 0 or doc_norm == 0:\n",
    "        return 0.0\n",
    "\n",
    "    similarity = dot_product / (query_norm * doc_norm)\n",
    "    return similarity\n",
    "\n",
    "#Rank documents based on similarity score\n",
    "def rank_documents(query_vector, matched_docs, tf_idf_matrix):\n",
    "    ranked_documents = []\n",
    "\n",
    "    for doc in matched_docs:\n",
    "        doc_vector = np.array([tf_idf_matrix[term][doc] for term in tf_idf_matrix.keys()])\n",
    "        similarity_score = compute_similarity(query_vector, doc_vector)\n",
    "        ranked_documents.append((doc, similarity_score))\n",
    "\n",
    "    ranked_documents.sort(key=lambda x: x[1], reverse=True)\n",
    "    return ranked_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = r\"C:\\Users\\Abdelrahman Mostafa\\Desktop\\IR\\lastIR_project\\lastIR_project\\files\"\n",
    "data = read_files(data_directory)\n",
    "positional_index = build_positional_index(data)\n",
    "term_frequency = compute_term_frequency(positional_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example phrase query\n",
    "query_phrase = \"mercy\"\n",
    "matched_docs_phrase = phrase_query(positional_index, query_phrase)\n",
    "print(\"Matched Documents (Phrase Query):\", matched_docs_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Documents (Boolean Query): ['10.txt']\n"
     ]
    }
   ],
   "source": [
    "# Example boolean query\n",
    "query_boolean = \"fools and not angels\"\n",
    "matched_docs_boolean = boolean_query(positional_index, query_boolean)\n",
    "print(\"Matched Documents (Boolean Query):\", matched_docs_boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example computation of IDF for each term\n",
    "idf = {term: compute_idf(data, term) for term in positional_index}\n",
    "print(\"IDF for each term:\", idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example computation of TF-IDF matrix\n",
    "tf_idf_matrix = compute_tf_idf(term_frequency, idf)\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(tabulate(tf_idf_matrix, headers=\"keys\", tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_idf_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage with similarity and ranking\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Assuming you have a query and matched documents from the boolean query example\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m query_vector \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([tf_idf_matrix[term][\u001b[38;5;28mlist\u001b[39m(data\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtf_idf_matrix\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()])\n\u001b[0;32m      4\u001b[0m ranked_documents \u001b[38;5;241m=\u001b[39m rank_documents(query_vector, matched_docs_boolean, tf_idf_matrix)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Display the ranked documents in a table\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf_idf_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# Example usage with similarity and ranking\n",
    "# Assuming you have a query and matched documents from the boolean query example\n",
    "query_vector = np.array([tf_idf_matrix[term][list(data.keys())[0]] for term in tf_idf_matrix.keys()])\n",
    "ranked_documents = rank_documents(query_vector, matched_docs_boolean, tf_idf_matrix)\n",
    "\n",
    "# Display the ranked documents in a table\n",
    "table_data = []\n",
    "for rank, (doc, similarity_score) in enumerate(ranked_documents, start=1):\n",
    "    table_data.append([rank, doc, similarity_score])\n",
    "\n",
    "# Define headers for the table\n",
    "headers = [\"Rank\", \"Document ID\", \"Similarity Score\"]\n",
    "\n",
    "# Print the table\n",
    "print(\"Ranked Documents:\")\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"pretty\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
